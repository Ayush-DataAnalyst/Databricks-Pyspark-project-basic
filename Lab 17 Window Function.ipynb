{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a65020b8-2773-40c0-924b-d1118099348d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n| id|  name|country|salary|\n+---+------+-------+------+\n|  1|Manish|  india| 10000|\n|  2|  Rani|  india| 50000|\n|  3| Sunny|     UK|  5000|\n|  4| Soham|     UK| 25000|\n|  3|  Mona|  india| 10000|\n+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'Manish','india',10000),(2,'Rani','india',50000),(3,'Sunny','UK',5000),(4,'Soham','UK',25000),(3,'Mona','india',10000)]\n",
    "columns = ['id','name','country','salary']\n",
    "\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f2d6787-0741-4f04-9273-6d398cc5e854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+---+\n| id|  name|country|salary| rn|\n+---+------+-------+------+---+\n|  3| Sunny|     UK|  5000|  1|\n|  4| Soham|     UK| 25000|  2|\n|  1|Manish|  india| 10000|  1|\n|  3|  Mona|  india| 10000|  2|\n|  2|  Rani|  india| 50000|  3|\n+---+------+-------+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"country\").orderBy(\"salary\")\n",
    "df.withColumn(\"rn\", row_number().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "490a1d48-e50b-46ac-b15a-0a596ac8f30d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+---+\n| id|  name|country|salary| rn|\n+---+------+-------+------+---+\n|  3| Sunny|     UK|  5000|  1|\n|  4| Soham|     UK| 25000|  2|\n|  1|Manish|  india| 10000|  1|\n|  3|  Mona|  india| 10000|  2|\n|  2|  Rani|  india| 50000|  3|\n+---+------+-------+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"country\").orderBy(\"salary\")\n",
    "df.withColumn(\"rn\", row_number().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4e50e87-80b4-4f2b-8895-89d413cd0ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+---+\n| id|  name|country|salary| rn|\n+---+------+-------+------+---+\n|  4| Soham|     UK| 25000|  1|\n|  3| Sunny|     UK|  5000|  2|\n|  2|  Rani|  india| 50000|  1|\n|  1|Manish|  india| 10000|  2|\n|  3|  Mona|  india| 10000|  2|\n+---+------+-------+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "window = Window.partitionBy(\"country\").orderBy(col(\"salary\").desc())\n",
    "df.withColumn(\"rn\", rank().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6911b513-b218-498f-9c5b-8e9a9b870703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+---+\n| id|  name|country|salary| rn|\n+---+------+-------+------+---+\n|  3| Sunny|     UK|  5000|  1|\n|  4| Soham|     UK| 25000|  2|\n|  1|Manish|  india| 10000|  1|\n|  3|  Mona|  india| 10000|  1|\n|  2|  Rani|  india| 50000|  2|\n+---+------+-------+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"country\").orderBy(\"salary\")\n",
    "df.withColumn(\"rn\", dense_rank().over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "862747b5-ae73-4852-a37f-39fe7fdb55c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lab 17 Window Function",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}